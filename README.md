

# Receipt-OCR

![GitHub License](https://img.shields.io/badge/license-MIT-blue.svg) ![Python Version](https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10-blue)

Receipt-OCR is a Python-based Optical Character Recognition (OCR) tool designed to extract text and structured data from receipt images. This project is currently in its early stages of development and aims to automate the process of parsing receipts for expense tracking, financial analysis, or other applications.

As an intern project, this repository serves as a learning experience to explore OCR technologies, image processing, and software development best practices.


---

## About the Project
The goal of this project is to create a simple yet effective tool to extract useful information from receipt images, such as:
- Merchant name
- Transaction date
- Total amount
- Other relevant details

This project is being developed using Python and leverages libraries like Tesseract OCR for text extraction and OpenCV for image preprocessing. It’s a great way to learn about OCR, machine learning workflows, and software engineering practices.

---

## Features (Planned)
Here are some of the features we aim to implement:
- Extract text from receipt images.
- Parse structured data (e.g., merchant name, date, total amount).
- Support multiple output formats: JSON, CSV, and plain text.
- Add noise reduction and image enhancement for better accuracy.
- Create a user-friendly command-line interface (CLI).

---

## Getting Started

### Prerequisites
To run this project, you’ll need the following:
- Python 3.8 or higher


---
## Dataset
The dataset used for training and testing the OCR model consists of various receipt images. The dataset is not included in this repository due to size constraints, but you can find similar datasets online or create your own by scanning receipts.
links to datasets: (https://www.kaggle.com/datasets/trainingdatapro/ocr-receipts-text-detection)


---

## Acknowledgments
- **Mentors and Team**: Special thanks to my mentor **Hamza Hadda* and colleagues for their guidance and support during this internship.


